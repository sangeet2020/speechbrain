# Generated 2022-12-05 from:
# /netscratch/sagar/thesis/speechbrain/recipes/SAR/Tokenizer/hparams/1K_unigram_subword_bpe.yaml
# yamllint disable
# ############################################################################
# Tokenizer: subword BPE with char 1K
# Training: SAR domain dataset 100 mins
# Authors:  Abdel Heba 2021, Sangeet Sagar 2022
# ############################################################################

token_type: unigram    # ["unigram", "bpe", "char"]
dataset: sar_combined
output_folder: results/sar_combined/unigram
train_log: results/sar_combined/unigram/train_log.txt

# Data files
data_folder: ../dataset/sar_combined_dataset
csv_dir: ../csv_files/sar_combined
train_tsv_file: ../dataset/sar_combined_dataset/train.tsv
dev_tsv_file: ../dataset/sar_combined_dataset/dev.tsv
test_tsv_file: ../dataset/sar_combined_dataset/test.tsv
accented_letters: true
language: de
skip_prep: false

train_csv: ../csv_files/sar_combined/train.csv
valid_csv: ../csv_files/sar_combined/dev.csv

# Training parameters
token_output: 1000 # index(blank/eos/bos/unk) = 0
character_coverage: 1.0
csv_read: wrd
bos_id: -1
eos_id: -1

tokenizer: !name:speechbrain.tokenizers.SentencePiece.SentencePiece
  model_dir: results/sar_combined/unigram
  vocab_size: 1000
  annotation_train: ../csv_files/sar_combined/train.csv
  annotation_read: wrd
  model_type: unigram            # ["unigram", "bpe", "char"]
  character_coverage: 1.0
  annotation_list_to_check: [../csv_files/sar_combined/train.csv, ../csv_files/sar_combined/dev.csv]
  bos_id: -1
  eos_id: -1
